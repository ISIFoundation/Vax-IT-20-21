{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Detection General\n",
    "## In this notebook:\n",
    "For each time-specific dataset:\n",
    "* We import the matrix of raw count C (tweet-term matrix) and the fitted Count Vectorizer (the vocabulary) cv;\n",
    "* We fit the TFIDF method on the raw count matrix C;\n",
    "* We do idf normalization: to avoid the + 1 of the idf term (added to avoid division by zero), we subtract 1 to all the values in the idf vector;\n",
    "* We obtain the matrix X from the TFIDF and we fit the NMF method on the X;\n",
    "* We save to file the NMF, the W and the H and we print the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "import joblib\n",
    "from sklearn import feature_extraction\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_analyzer(text):\n",
    "    words = [w for w in token_pattern.findall(text.lower()) if w not in stop_words]\n",
    "    return bigram[words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[C0, cv0] = joblib.load('/../data/counts_vocabulary_i.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#apply the tfidf weighting\n",
    "tfidf = feature_extraction.text.TfidfTransformer()\n",
    "tfidf.fit(C0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#tfidf normalization: to avoid the + 1 of the idf term (added to avoid division by zero)\n",
    "tfidf.idf_ = tfidf.idf_ - 1\n",
    "X = tfidf.transform(C0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#fit the non-negative matrix factorization\n",
    "nr_topics = 20\n",
    "nmf = decomposition.NMF(nr_topics,\n",
    "                        beta_loss='frobenius', solver='cd',\n",
    "                        init='nndsvd', random_state=42)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape, H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the fitted tfidf object\n",
    "joblib.dump(tfidf, '/../data/tfidf_i.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saving nmf results\n",
    "joblib.dump([W,H,nmf], '/../data/WHnmf_i.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains the vocabulary\n",
    "cv0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#printing topics\n",
    "feature_names = np.array(cv0.get_feature_names())\n",
    "topic_strength = W.sum(axis=0)\n",
    "for i in topic_strength.argsort()[::-1]:\n",
    "    topic_words = feature_names[np.argsort(H[i])[::-1][:10]]\n",
    "    print(\"[T %d] Stenght: %.2f, words: \" % (i, topic_strength[i]), \",\".join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del C0, cv0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## early-COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[C1, cv1] = joblib.load('/../data/counts_vocabulary_ii.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#apply the tfidf weighting\n",
    "tfidf = feature_extraction.text.TfidfTransformer()\n",
    "tfidf.fit(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#tfidf normalization: to avoid the + 1 of the idf term (added to avoid division by zero)\n",
    "tfidf.idf_ = tfidf.idf_ - 1\n",
    "X = tfidf.transform(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#fit the non-negative matrix factorization\n",
    "nr_topics = 20\n",
    "nmf = decomposition.NMF(nr_topics,\n",
    "                        beta_loss='frobenius', solver='cd',\n",
    "                        init='nndsvd', random_state=42)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape, H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the fitted tfidf object\n",
    "joblib.dump(tfidf, '/../data/tfidf_ii.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saving nmf results\n",
    "joblib.dump([W,H,nmf], '/../data/WHnmf_ii.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains the vocabulary\n",
    "cv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#printing topics\n",
    "feature_names = np.array(cv1.get_feature_names())\n",
    "topic_strength = W.sum(axis=0)\n",
    "for i in topic_strength.argsort()[::-1]:\n",
    "    topic_words = feature_names[np.argsort(H[i])[::-1][:10]]\n",
    "    print(\"[T %d] Stenght: %.2f, words: \" % (i, topic_strength[i]), \",\".join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del C1, cv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-VAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[C2, cv2] = joblib.load('/../data/counts_vocabulary_iii.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#apply the tfidf weighting\n",
    "tfidf = feature_extraction.text.TfidfTransformer()\n",
    "tfidf.fit(C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#tfidf normalization: to avoid the + 1 of the idf term (added to avoid division by zero)\n",
    "tfidf.idf_ = tfidf.idf_ - 1\n",
    "X = tfidf.transform(C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#fit the non-negative matrix factorization\n",
    "nr_topics = 20\n",
    "nmf = decomposition.NMF(nr_topics,\n",
    "                        beta_loss='frobenius', solver='cd',\n",
    "                        init='nndsvd', random_state=42)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape, H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the fitted tfidf object\n",
    "joblib.dump(tfidf, '/../data/tfidf_iii.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saving nmf results\n",
    "joblib.dump([W,H,nmf], '/../data/WHnmf_iii.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains the vocabulary\n",
    "cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#printing topics\n",
    "feature_names = np.array(cv2.get_feature_names())\n",
    "topic_strength = W.sum(axis=0)\n",
    "for i in topic_strength.argsort()[::-1]:\n",
    "    topic_words = feature_names[np.argsort(H[i])[::-1][:10]]\n",
    "    print(\"[T %d] Stenght: %.2f, words: \" % (i, topic_strength[i]), \",\".join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del C2, cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## early-VAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[C3, cv3] = joblib.load('/../data/counts_vocabulary_iv.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#apply the tfidf weighting\n",
    "tfidf = feature_extraction.text.TfidfTransformer()\n",
    "tfidf.fit(C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#tfidf normalization: to avoid the + 1 of the idf term (added to avoid division by zero)\n",
    "tfidf.idf_ = tfidf.idf_ - 1\n",
    "X = tfidf.transform(C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#fit the non-negative matrix factorization\n",
    "nr_topics = 20\n",
    "nmf = decomposition.NMF(nr_topics,\n",
    "                        beta_loss='frobenius', solver='cd',\n",
    "                        init='nndsvd', random_state=42)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape, H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the fitted tfidf object\n",
    "joblib.dump(tfidf, '/../data/tfidf_iv.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saving nmf results\n",
    "joblib.dump([W,H,nmf], '/../data/WHnmf_iv.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains the vocabulary\n",
    "cv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#printing topics\n",
    "feature_names = np.array(cv3.get_feature_names())\n",
    "topic_strength = W.sum(axis=0)\n",
    "for i in topic_strength.argsort()[::-1]:\n",
    "    topic_words = feature_names[np.argsort(H[i])[::-1][:10]]\n",
    "    print(\"[T %d] Stenght: %.2f, words: \" % (i, topic_strength[i]), \",\".join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del C3, cv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAX-drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[C4, cv4] = joblib.load('/../data/counts_vocabulary_v.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#apply the tfidf weighting\n",
    "tfidf = feature_extraction.text.TfidfTransformer()\n",
    "tfidf.fit(C4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#tfidf normalization: to avoid the + 1 of the idf term (added to avoid division by zero)\n",
    "tfidf.idf_ = tfidf.idf_ - 1\n",
    "X = tfidf.transform(C4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#fit the non-negative matrix factorization\n",
    "nr_topics = 20\n",
    "nmf = decomposition.NMF(nr_topics,\n",
    "                        beta_loss='frobenius', solver='cd',\n",
    "                        init='nndsvd', random_state=42)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape, H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the fitted tfidf object\n",
    "joblib.dump(tfidf, '/../data/tfidf_v.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saving nmf results\n",
    "joblib.dump([W,H,nmf], '/../data/WHnmf_v.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains the vocabulary\n",
    "cv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#printing topics\n",
    "feature_names = np.array(cv4.get_feature_names())\n",
    "topic_strength = W.sum(axis=0)\n",
    "for i in topic_strength.argsort()[::-1]:\n",
    "    topic_words = feature_names[np.argsort(H[i])[::-1][:10]]\n",
    "    print(\"[T %d] Stenght: %.2f, words: \" % (i, topic_strength[i]), \",\".join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del C4, cv4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## late-VAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[C5, cv5] = joblib.load('/../data/counts_vocabulary_vi.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#apply the tfidf weighting\n",
    "tfidf = feature_extraction.text.TfidfTransformer()\n",
    "tfidf.fit(C5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#tfidf normalization: to avoid the + 1 of the idf term (added to avoid division by zero)\n",
    "tfidf.idf_ = tfidf.idf_ - 1\n",
    "X = tfidf.transform(C5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#fit the non-negative matrix factorization\n",
    "nr_topics = 20\n",
    "nmf = decomposition.NMF(nr_topics,\n",
    "                        beta_loss='frobenius', solver='cd',\n",
    "                        init='nndsvd', random_state=42)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape, H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the fitted tfidf object\n",
    "joblib.dump(tfidf, '/../data/tfidf_vi.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saving nmf results\n",
    "joblib.dump([W,H,nmf], '/../data/WHnmf_vi.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains the vocabulary\n",
    "cv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#printing topics\n",
    "feature_names = np.array(cv5.get_feature_names())\n",
    "topic_strength = W.sum(axis=0)\n",
    "for i in topic_strength.argsort()[::-1]:\n",
    "    topic_words = feature_names[np.argsort(H[i])[::-1][:10]]\n",
    "    print(\"[T %d] Stenght: %.2f, words: \" % (i, topic_strength[i]), \",\".join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del C5, cv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
