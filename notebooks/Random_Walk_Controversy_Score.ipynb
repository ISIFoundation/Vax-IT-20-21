{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walk Controversy score (RWC)\n",
    "## In this notebook:\n",
    "* For each time period we define $H$ and $S$ subgroups of nodes, where $H$ is the set of users forming the vaccine hesitant community and $S$ is the set of users forming the vaccine supporters community.\n",
    "* We remove PET users and leave UNASSIGNED users.\n",
    "* We compute the RWC for all the retweet networks, as well as $H \\rightarrow S$ and $S \\rightarrow H$ probabilities, where $prob(H \\rightarrow S)$ is the contidional probability for a random walker to have started in $H$ given that it has ended in $S$.  \n",
    "* We use $K=100$ as the number of most important nodes per side.\n",
    "* We plot both the RWC score and the transition probabilities on a 2Y-axes plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import heapq\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to simulate randomwalk with restart using the personalized page rank from networkx.\n",
    "\n",
    "# uses the same intuition as the randomwalk score in the WSDM paper. What is the probability that a randomwalk \n",
    "# ending in a particular side started on the other side.\n",
    "\n",
    "# we need networkx > 1.10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = pd.read_csv('/../data/alltime_edgelist.csv').drop(['Unnamed: 0'],axis=1)\n",
    "t[t['weight'] > 1] #applying filter on edges' weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usrs_net_df0 = t[t['time_window'] == 'i']\n",
    "usrs_net_df1 = t[t['time_window'] == 'ii']\n",
    "usrs_net_df2 = t[t['time_window'] == 'iii']\n",
    "usrs_net_df3 = t[t['time_window'] == 'iv']\n",
    "usrs_net_df4 = t[t['time_window'] == 'v']\n",
    "usrs_net_df5 = t[t['time_window'] == 'vi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I apply the filter on the weight. I discard links with weight = 1\n",
    "G0w = nx.from_pandas_edgelist(usrs_net_df0[usrs_net_df0['weight'] > 1], source='user1', target='user2', edge_attr=True, create_using=nx.DiGraph())\n",
    "G1w = nx.from_pandas_edgelist(usrs_net_df1[usrs_net_df1['weight'] > 1], source='user1', target='user2', edge_attr=True, create_using=nx.DiGraph())\n",
    "G2w = nx.from_pandas_edgelist(usrs_net_df2[usrs_net_df2['weight'] > 1], source='user1', target='user2', edge_attr=True, create_using=nx.DiGraph())\n",
    "G3w = nx.from_pandas_edgelist(usrs_net_df3[usrs_net_df3['weight'] > 1], source='user1', target='user2', edge_attr=True, create_using=nx.DiGraph())\n",
    "G4w = nx.from_pandas_edgelist(usrs_net_df4[usrs_net_df4['weight'] > 1], source='user1', target='user2', edge_attr=True, create_using=nx.DiGraph())\n",
    "G5w = nx.from_pandas_edgelist(usrs_net_df5[usrs_net_df5['weight'] > 1], source='user1', target='user2', edge_attr=True, create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del G0w,G1w,G2w,G3w,G4w,G5w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the GCC out of the network obtained by the application of the filter weight > 1\n",
    "wcc0_w = max(nx.weakly_connected_components(G0w), key=len) \n",
    "wcc0_w = G0w.subgraph(wcc0_w).copy()\n",
    "\n",
    "wcc1_w = max(nx.weakly_connected_components(G1w), key=len) \n",
    "wcc1_w = G1w.subgraph(wcc1_w).copy()\n",
    "\n",
    "wcc2_w = max(nx.weakly_connected_components(G2w), key=len) \n",
    "wcc2_w = G2w.subgraph(wcc2_w).copy()\n",
    "\n",
    "wcc3_w = max(nx.weakly_connected_components(G3w), key=len) \n",
    "wcc3_w = G3w.subgraph(wcc3_w).copy()\n",
    "\n",
    "wcc4_w = max(nx.weakly_connected_components(G4w), key=len) \n",
    "wcc4_w = G4w.subgraph(wcc4_w).copy()\n",
    "\n",
    "wcc5_w = max(nx.weakly_connected_components(G5w), key=len) \n",
    "wcc5_w = G5w.subgraph(wcc5_w).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N0wcc_w, N1wcc_w, N2wcc_w, N3wcc_w, N4wcc_w, N5wcc_w = wcc0_w.number_of_nodes(), wcc1_w.number_of_nodes(), wcc2_w.number_of_nodes(), wcc3_w.number_of_nodes(), wcc4_w.number_of_nodes(), wcc5_w.number_of_nodes()\n",
    "n0wcc_w, n1wcc_w, n2wcc_w, n3wcc_w, n4wcc_w, n5wcc_w = wcc0_w.number_of_edges(), wcc1_w.number_of_edges(), wcc2_w.number_of_edges(), wcc3_w.number_of_edges(), wcc4_w.number_of_edges(), wcc5_w.number_of_edges()\n",
    "\n",
    "print('i   -> Number of nodes:', N0wcc_w, ', number of edges', n0wcc_w)\n",
    "print('ii  -> Number of nodes:', N1wcc_w, ', number of edges', n1wcc_w)\n",
    "print('iii -> Number of nodes:', N2wcc_w, ', number of edges', n2wcc_w)\n",
    "print('iv  -> Number of nodes:', N3wcc_w, ', number of edges', n3wcc_w)\n",
    "print('v   -> Number of nodes:', N4wcc_w, ', number of edges', n4wcc_w)\n",
    "print('vi  -> Number of nodes:', N5wcc_w, ', number of edges', n5wcc_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcc5_w.is_directed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing nodes dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n is a dataframe like: id_usr, RMC, community, time_window \n",
    "n = pd.read_csv('/../data/nodes_example_i_vi.csv',dtype=str).drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "n0 = n[n['time_window'] == 'i']\n",
    "n1 = n[n['time_window'] == 'ii']\n",
    "n2 = n[n['time_window'] == 'iii']\n",
    "n3 = n[n['time_window'] == 'iv']\n",
    "n4 = n[n['time_window'] == 'v']\n",
    "n5 = n[n['time_window'] == 'vi']\n",
    "\n",
    "#vaccine hesitant community i: 1\n",
    "#vaccine hesitant community ii: 3\n",
    "#vaccine hesitant community iii: 1\n",
    "#vaccine hesitant community iv: 1\n",
    "#vaccine hesitant community v: 1\n",
    "#vaccine hesitant community vi: 1\n",
    "\n",
    "av0 = set(n0[n0['community'] == '1'].id_usr)\n",
    "av1 = set(n1[n1['community'] == '3'].id_usr)\n",
    "av2 = set(n2[n2['community'] == '1'].id_usr)\n",
    "av3 = set(n3[n3['community'] == '1'].id_usr)\n",
    "av4 = set(n4[n4['community'] == '1'].id_usr)\n",
    "av5 = set(n5[n5['community'] == '1'].id_usr)\n",
    "\n",
    "\n",
    "#vaccine supporters community i: 3\n",
    "#vaccine supporters community ii: 1\n",
    "#vaccine supporters community iii: 2\n",
    "#vaccine supporters community iv: 2\n",
    "#vaccine supporters community v: 2\n",
    "#vaccine supporters community vi: 2\n",
    "\n",
    "\n",
    "pv0 = set(n0[n0['community'] == '3'].id_usr)\n",
    "pv1 = set(n1[n1['community'] == '1'].id_usr)\n",
    "pv2 = set(n2[n2['community'] == '2'].id_usr)\n",
    "pv3 = set(n3[n3['community'] == '2'].id_usr)\n",
    "pv4 = set(n4[n4['community'] == '2'].id_usr)\n",
    "pv5 = set(n5[n5['community'] == '2'].id_usr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a dict with uniform distribution to that particular side and close-to-zero to the other side    \n",
    "def getUniformDistribution(part_start, part_end, epsilon=1e-12):\n",
    "    uniform = {k:1.0/len(part_start) for k in part_start}\n",
    "    uniform.update({k:epsilon for k in part_end})\n",
    "    return uniform\n",
    "\n",
    "def getNodesFromPartitionWithHighestDegree(G, k, part):\n",
    "    # top-k largest nodes by in-degree in the given partition\n",
    "    return heapq.nlargest(k, G.in_degree(part), key=itemgetter(1))\n",
    "\n",
    "def rwc_score(G, partition, k=10, alpha=0.85, max_iter=100000):\n",
    "    # G is a NetworkX weighted directed graph\n",
    "    # partition is a dictionary side->set(nodes) where side \\in {0,1}\n",
    "    part_left  = partition[0] #nodes of the left partition\n",
    "    part_right = partition[1] #nodes of the right partition\n",
    "    \n",
    "    uniform_left   = getUniformDistribution(part_left, part_right)\n",
    "    #print(uniform_left,type(uniform_left))\n",
    "    pagerank_left  = nx.pagerank(G, alpha=alpha, \\\n",
    "                            personalization=uniform_left, \\\n",
    "                            dangling=uniform_left, max_iter=max_iter);\n",
    "\n",
    "    uniform_right  = getUniformDistribution(part_right, part_left)\n",
    "    pagerank_right = nx.pagerank(G, alpha=alpha, \\\n",
    "                            personalization=uniform_right, \\\n",
    "                            dangling=uniform_right, max_iter=max_iter);\n",
    "\n",
    "    top_nodes_left  = getNodesFromPartitionWithHighestDegree(G, k, part_left)\n",
    "    top_nodes_right = getNodesFromPartitionWithHighestDegree(G, k, part_right)\n",
    "        \n",
    "    start_left_end_left   = sum([pagerank_left[k]  for k,v in top_nodes_left])\n",
    "    start_left_end_right  = sum([pagerank_left[k]  for k,v in top_nodes_right])\n",
    "    start_right_end_left  = sum([pagerank_right[k] for k,v in top_nodes_left])\n",
    "    start_right_end_right = sum([pagerank_right[k] for k,v in top_nodes_right])\n",
    "    \n",
    "    left_ratio  = float(len(part_left))  / G.number_of_nodes()\n",
    "    right_ratio = float(len(part_right)) / G.number_of_nodes()\n",
    "    \n",
    "    p_start_left_end_left = (start_left_end_left * left_ratio)/ \\\n",
    "        ((start_left_end_left * left_ratio) + (start_right_end_left * right_ratio));\n",
    "\n",
    "    p_start_left_end_right = (start_left_end_right * left_ratio)/ \\\n",
    "        ((start_right_end_right * right_ratio) + (start_left_end_right * left_ratio));\n",
    "\n",
    "    p_start_right_end_right = (start_right_end_right * right_ratio)/ \\\n",
    "        ((start_right_end_right * right_ratio) + (start_left_end_right * left_ratio));\n",
    "\n",
    "    p_start_right_end_left = (start_right_end_left * right_ratio)/ \\\n",
    "        ((start_left_end_left * left_ratio) + (start_right_end_left * right_ratio));\n",
    "\n",
    "    #     print(\"left  -> left \", p_start_left_end_left)\n",
    "    #     print(\"right -> left \", p_start_right_end_left)\n",
    "    #     print(\"left  -> right\", p_start_left_end_right)\n",
    "    #     print(\"right -> right\", p_start_right_end_right)\n",
    "\n",
    "\n",
    "    rwc_score = p_start_left_end_left*p_start_right_end_right - p_start_left_end_right*p_start_right_end_left\n",
    "    print (rwc_score)\n",
    "    print({'hh': p_start_left_end_left,\n",
    "           'ss': p_start_right_end_right,\n",
    "           'hs': p_start_left_end_right,\n",
    "           'sh': p_start_right_end_left})\n",
    "    \n",
    "    return rwc_score, p_start_left_end_left, p_start_right_end_right, p_start_left_end_right, p_start_right_end_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing RWC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('preCOVID |V|:\\t',wcc0_w.number_of_nodes(),'\\t |E|:',wcc0_w.number_of_edges())\n",
    "print('earlyCOVID |V|:\\t',wcc1_w.number_of_nodes(),'\\t |E|:',wcc1_w.number_of_edges())\n",
    "print('preVAX |V|:\\t',wcc2_w.number_of_nodes(),'\\t |E|:',wcc2_w.number_of_edges())\n",
    "print('earlyVAX |V|:\\t',wcc3_w.number_of_nodes(),'\\t |E|:',wcc3_w.number_of_edges())\n",
    "print('VAXdrive |V|:\\t',wcc4_w.number_of_nodes(),'\\t |E|:',wcc4_w.number_of_edges())\n",
    "print('lateVAX |V|:\\t',wcc5_w.number_of_nodes(),'\\t |E|:',wcc5_w.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0.index = n0.id_usr\n",
    "n1.index = n1.id_usr\n",
    "n2.index = n2.id_usr\n",
    "n3.index = n3.id_usr\n",
    "n4.index = n4.id_usr\n",
    "n5.index = n5.id_usr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add attributes to nodes\n",
    "nx.set_node_attributes(wcc0_w,values=n0['community'].to_dict(),name='community')\n",
    "nx.set_node_attributes(wcc0_w,values=n0['RMC'].to_dict(),name='RMC')\n",
    "\n",
    "nx.set_node_attributes(wcc1_w,values=n1['community'].to_dict(),name='community')\n",
    "nx.set_node_attributes(wcc1_w,values=n1['RMC'].to_dict(),name='RMC')\n",
    "\n",
    "nx.set_node_attributes(wcc2_w,values=n2['community'].to_dict(),name='community')\n",
    "nx.set_node_attributes(wcc2_w,values=n2['RMC'].to_dict(),name='RMC')\n",
    "\n",
    "nx.set_node_attributes(wcc3_w,values=n3['community'].to_dict(),name='community')\n",
    "nx.set_node_attributes(wcc3_w,values=n3['RMC'].to_dict(),name='RMC')\n",
    "\n",
    "nx.set_node_attributes(wcc4_w,values=n4['community'].to_dict(),name='community')\n",
    "nx.set_node_attributes(wcc4_w,values=n4['RMC'].to_dict(),name='RMC')\n",
    "\n",
    "nx.set_node_attributes(wcc5_w,values=n5['community'].to_dict(),name='community')\n",
    "nx.set_node_attributes(wcc5_w,values=n5['RMC'].to_dict(),name='RMC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING ONLY PET NODES\n",
    "#pet community preCOVID: 2\n",
    "#pet community earlyCOVID: 2\n",
    "#pet community preVAX: 3\n",
    "\n",
    "nodes0_0 = []\n",
    "for (p, d) in wcc0_w.nodes(data=True):\n",
    "    if d['community'] == '2': #removing pet users\n",
    "        nodes0_0.append(p)\n",
    "\n",
    "nodes0_1 = []\n",
    "for (p, d) in wcc1_w.nodes(data=True):\n",
    "    if d['community'] == '2':\n",
    "        nodes0_1.append(p)\n",
    "\n",
    "nodes0_2 = []\n",
    "for (p, d) in wcc2_w.nodes(data=True):\n",
    "    if d['community'] == '3':\n",
    "        nodes0_2.append(p)\n",
    "\n",
    "wcc0_w.remove_nodes_from(nodes0_0)\n",
    "wcc1_w.remove_nodes_from(nodes0_1)\n",
    "wcc2_w.remove_nodes_from(nodes0_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('preCOVID |V|:\\t',wcc0_w.number_of_nodes(),'\\t |E|:',wcc0_w.number_of_edges())\n",
    "print('earlyCOVID |V|:\\t',wcc1_w.number_of_nodes(),'\\t |E|:',wcc1_w.number_of_edges())\n",
    "print('preVAX |V|:\\t',wcc2_w.number_of_nodes(),'\\t |E|:',wcc2_w.number_of_edges())\n",
    "print('earlyVAX |V|:\\t',wcc3_w.number_of_nodes(),'\\t |E|:',wcc3_w.number_of_edges())\n",
    "print('VAXdrive |V|:\\t',wcc4_w.number_of_nodes(),'\\t |E|:',wcc4_w.number_of_edges())\n",
    "print('lateVAX |V|:\\t',wcc5_w.number_of_nodes(),'\\t |E|:',wcc5_w.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* preCOVID |V|:  5528 \t |E|: 18409\n",
    "* earlyCOVID |V|:4247 \t |E|: 9054\n",
    "* preVAX |V|:\t 18967 \t |E|: 80234\n",
    "* earlyVAX |V|:\t 59398 \t |E|: 410515\n",
    "* VAXdrive |V|:\t 43325 \t |E|: 318284\n",
    "* lateVAX |V|:\t 44840 \t |E|: 451118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of important nodes\n",
    "K = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preCOVID\n",
    "partition = {0:pv0, 1:av0}\n",
    "rwc0,ll0,rr0,lr0,rl0 = rwc_score(wcc0_w, partition, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#earlyCOVID\n",
    "partition = {0:pv1, 1:av1}\n",
    "rwc1,ll1,rr1,lr1,rl1 = rwc_score(wcc1_w, partition, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preVAX\n",
    "partition = {0:pv2, 1:av2}\n",
    "rwc2,ll2,rr2,lr2,rl2 = rwc_score(wcc2_w, partition, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#earlyVAX\n",
    "partition = {0:pv3, 1:av3}\n",
    "rwc3,ll3,rr3,lr3,rl3 = rwc_score(wcc3_w, partition, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAXdrive\n",
    "partition = {0:pv4, 1:av4}\n",
    "rwc4,ll4,rr4,lr4,rl4 = rwc_score(wcc4_w, partition, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lateVAX\n",
    "partition = {0:pv5, 1:av5}\n",
    "rwc5,ll5,rr5,lr5,rl5 = rwc_score(wcc5_w, partition, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarizing into a table\n",
    "table = {\n",
    "    \n",
    "    'RWC': [np.round(rwc0,4),np.round(rwc1,4),np.round(rwc2,4),\n",
    "                 np.round(rwc3,4),np.round(rwc4,4),np.round(rwc5,4)],\n",
    "    'hh prob': [np.round(ll0,4),np.round(ll1,4),np.round(ll2,4),\n",
    "                 np.round(ll3,4),np.round(ll4,4),np.round(ll5,4)],\n",
    "    'sh prob': [np.round(rl0,4),np.round(rl1,4),np.round(rl2,4),\n",
    "                 np.round(rl3,4),np.round(rl4,4),np.round(rl5,4)],\n",
    "    'hs prob': [np.round(lr0,4),np.round(lr1,4),np.round(lr2,4),\n",
    "                 np.round(lr3,4),np.round(lr4,4),np.round(lr5,4)],\n",
    "    'ss prob': [np.round(rr0,4),np.round(rr1,4),np.round(rr2,4),\n",
    "                 np.round(rr3,4),np.round(rr4,4),np.round(rr5,4)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = pd.DataFrame(table)\n",
    "table_df.index = ['preCOVID','earlyCOVID','preVAX','earlyVAX','VAXdrive','lateVAX']\n",
    "table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Y axis plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwcs = [rwc0,rwc1,rwc2,rwc3,rwc4,rwc5]\n",
    "rls = [rl0,rl1,rl2,rl3,rl4,rl5]\n",
    "lrs = [lr0,lr1,lr2,lr3,lr4,lr5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create some mock data\n",
    "#t = np.arange(0, 6, 1)\n",
    "t = ['i','ii','iii','iv','v','vi']\n",
    "data1 = rwcs \n",
    "data2 = rls \n",
    "data3 = lrs \n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "fig.set_size_inches(8,4)\n",
    "\n",
    "color = 'purple'\n",
    "\n",
    "ax1.set_xlabel('time window', fontsize = 15)\n",
    "ax1.set_ylabel('RWC', color='black',fontsize=15)\n",
    "ax1.plot(t, data1, marker='s', linestyle='-' ,markersize=10, color=color, label='RWC')\n",
    "ax1.tick_params(axis='y', labelcolor='black')\n",
    "ax1.legend(fontsize=12)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'black'\n",
    "color1 = 'darkslategray'\n",
    "color2 = 'darkslategray'\n",
    "ax2.set_ylabel('transition probability', color='black', fontsize=15)\n",
    "ax2.plot(t, data2, color=color1, marker='o', linestyle='--', markersize=10, label='S'+r'$\\rightarrow$'+'H')\n",
    "ax2.plot(t, data3, color=color2, marker='^', linestyle=':', markersize=10, label='H'+r'$\\rightarrow$'+'S')\n",
    "ax2.legend(loc='lower right', fontsize=12)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clippe\n",
    "plt.savefig('/../figures/RWC_HSSH_probs.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
